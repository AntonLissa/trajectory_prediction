{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonLissa/trajectory_prediction/blob/main/CV_1_data_acquisition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get cars trajectories using supervision"
      ],
      "metadata": {
        "id": "0tlzeIRFEgfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "%cd 'drive/MyDrive/CV_project'\n",
        "\n",
        "!pip install supervision\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import supervision as sv\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "import ultralytics\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "irP8xvT2i36W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = YOLO('yolov8x.pt')\n",
        "model.fuse\n",
        "\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "selected_classes = [2,3,5,7] # cars, bus, motorbikes, trucks"
      ],
      "metadata": {
        "id": "qwc8c4MQY7fy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "file_name = 'incrocio_1h'\n",
        "SOURCE_VIDEO_PATH = 'videos/' + file_name + '.mp4'\n",
        "TARGET_VIDEO_PATH = 'videos/processed/' + file_name +'_processed.mp4'\n",
        "info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frames_to_process = 2 # we process one frame every 2 for faster execution\n",
        "print(info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzttX1epZ1PK",
        "outputId": "30c44588-f653-4e68-c9db-c4f3d7d73e55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoInfo(width=1280, height=680, fps=30, total_frames=102449)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Creare un dizionario per salvare gli ID degli oggetti e i rispettivi centri\n",
        "object_centers = defaultdict(list)\n",
        "\n",
        "byte_tracker = sv.ByteTrack(track_thresh=0.5, track_buffer=30, match_thresh=0.8, frame_rate=30)\n",
        "\n",
        "\n",
        "# define call back function to be used in video processing\n",
        "def callback(frame: np.ndarray, index:int) -> np.ndarray:\n",
        "    if index % frames_to_process == 0: # for fastere execution use 1 frame every frame_to_process\n",
        "        print(index, '/', info.total_frames)\n",
        "\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame, verbose=False)[0]\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "        # only consider class id from selected_classes define above\n",
        "        detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "        # tracking detections\n",
        "        detections = byte_tracker.update_with_detections(detections)\n",
        "\n",
        "        # add object centers to the id\n",
        "        for box, id in zip(detections.xyxy, detections.tracker_id):\n",
        "                center = (\n",
        "            int((box[0] + box[2]) / 2),  # center X coord\n",
        "            int((box[1] + box[3]) / 2)   # center Y coord\n",
        "        )\n",
        "                object_centers[id].append(center)\n",
        "\n",
        "        return  frame\n",
        "\n",
        "# process the whole video\n",
        "sv.process_video(\n",
        "    source_path = SOURCE_VIDEO_PATH,\n",
        "    target_path = TARGET_VIDEO_PATH,\n",
        "    callback=callback\n",
        ")"
      ],
      "metadata": {
        "id": "V0fyFFOeZWOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the data obtained from the detections"
      ],
      "metadata": {
        "id": "LDQrTA6-ETX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Carica il frame dal video\n",
        "cap = cv2.VideoCapture('videos/incrocio_mod.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "# Visualize a frame from the video\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "print('numero di traiettorie:', len(object_centers.items()))\n",
        "# Draw trajectories\n",
        "for key, value in object_centers.items():\n",
        "    x, y = zip(*value)\n",
        "    plt.scatter(x, y, s = 3, c='blue')\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('Trajectories')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3IeISRF5gAPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data into a csv file"
      ],
      "metadata": {
        "id": "N4qTyatpIqlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "csv_file_path = 'trajectories/' + file_name +'.csv'\n",
        "\n",
        "\n",
        "data = []\n",
        "for key, value in object_centers.items():\n",
        "    trajectory = {\n",
        "        'Key': key,\n",
        "        'X': [point[0] for point in value],\n",
        "        'Y': [point[1] for point in value]\n",
        "    }\n",
        "    data.append(trajectory)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "XaDsgyyeh-vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GzMGRQGYi1Hf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}